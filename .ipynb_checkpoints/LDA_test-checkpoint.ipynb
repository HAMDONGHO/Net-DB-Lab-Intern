{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# tfidfv = TfidfVectorizer().fit([\"뿔\"])\n",
    "\n",
    "# # count_model = CountVectorizer(ngram_range=(1,1)) # default unigram model\n",
    "#\n",
    "# print(tfidfv.transform(['뿔']).toarray())\n",
    "# tfidf_vectorizer.fit(keyword_result)\n",
    "data = pd.read_csv('file_data_2020-08-01_to_2020-08-15.csv', error_bad_lines=False)\n",
    "\n",
    "print(len(data))\n",
    "sel =  data[data.date == '2020-08-01'][['text']]\n",
    "sel['text'] = sel.apply(lambda row : nltk.word_tokenize(row['text']), axis=1)\n",
    "# sel.apply\n",
    "print(sel)\n",
    "#\n",
    "# with open('file_data_2020-08-01_to_2020-08-15.csv','r', -1, encoding='utf-8') as csvfile:\n",
    "#     rows = csv.DictReader(csvfile, delimiter=',')\n",
    "#     datas = {}\n",
    "#     count = 0\n",
    "#     for row in rows:\n",
    "#         if row['date'] not in datas :\n",
    "#             datas[row['date']] = []\n",
    "#         datas[row['date']].append(row['text'])\n",
    "#         count +=1\n",
    "#     print(count)\n",
    "#     print(datas['2020-08-01'].head(5))\n",
    "\n",
    "    # tdm = TermDocumentMatrix(Corpus(VectorSource(datas['2020-08-01'])),\n",
    "    #                       control = list(removeNumbers = T,       # 숫자 없애기\n",
    "    #                                      removePunctuation = T,   # 기호 없애기\n",
    "    #                                      stopwords = T,           # 스탑워즈 없애기\n",
    "    #                                      wordLength = c(3, Inf)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # tfidfv = TfidfVectorizer().fit(datas['2020-08-01'])\n",
    "    # count_model = CountVectorizer(ngram_range=(1,1)) # default unigram model\n",
    "    # X = count_model.fit_transform(datas['2020-08-01'])\n",
    "    # Xc = (X.T * X) # this is co-occurrence matrix in sparse csr format\n",
    "    # Xc.setdiag(0) # sometimes you want to fill same word cooccurence to 0\n",
    "    # # print(tfidfv.transform(datas['2020-08-01']).toarray())\n",
    "    # top = 0\n",
    "    # topv = ''\n",
    "    # # res = sorted(tfidfv.vocabulary_.items(), key=(lambda x:x[1]))\n",
    "    # # print(res)\n",
    "    #\n",
    "    # print(Xc.todense())\n",
    "    # print(count_model.vocabulary_)\n",
    "\n",
    "# X[X > 0] = 1 # run this line if you don't want extra within-text cooccurence (see below)\n",
    "    # for v in tfidfv.vocabulary_:\n",
    "    #     if tfidfv.vocabulary_[v] > top :\n",
    "    #         topv = v\n",
    "    #         top = tfidfv.vocabulary_[v]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
